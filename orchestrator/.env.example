# Claw Pen Orchestrator Config
# Copy to .env and fill in values

# Deployment mode: windows-wsl | linux-native | all-windows
DEPLOYMENT_MODE=windows-wsl

# Network backend: tailscale | wireguard | zerotier | headscale | local
NETWORK_BACKEND=tailscale

# Tailscale auth key (only if using tailscale/headscale)
# TAILSCALE_AUTH_KEY=tskey-auth-xxx

# Unix socket path for container runtime IPC
# For WSL2: path inside WSL filesystem
RUNTIME_SOCKET=/var/run/claw-pen.sock

# Model Server Endpoints (for local LLMs)
# These are shared by agents configured to use local providers

# Ollama (default port)
# MODEL_SERVERS__OLLAMA__ENDPOINT=http://localhost:11434
# MODEL_SERVERS__OLLAMA__DEFAULT_MODEL=llama3.2

# llama.cpp server
# MODEL_SERVERS__LLAMA_CPP__ENDPOINT=http://localhost:8080

# vLLM server
# MODEL_SERVERS__VLLM__ENDPOINT=http://localhost:8000
